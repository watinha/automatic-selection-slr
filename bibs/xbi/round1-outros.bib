@article{1915,
 abstract = {Testing is paramount in order to assure the quality of a software product. Over the last years, several techniques have been proposed to leverage the testing phase as a simple and efficient step during software development. However, the features of the web environment make application testing fairly complex. The existing approaches for web application testing are usually driven to specific scenarios or application types, and few solutions are targeted for testing the functional requirements of applications. In order to tackle this problem, we propose a task-based testing approach that provides high coverage of functional requirements. Our technique consists of reassembling classical graph algorithms in order to generate all the possible paths for the execution of a task. Performed experiments indicate that our approach is effective for supporting the functional testing of web applications.},
 duplicado = {false},
 inserir = {false},
 title = {Leveraging task-based data to support functional testing of web applications},
 year = {2015}
}

@article{1917,
 abstract = {Today's enterprise web applications demand very high release cycles---and consequently, frequent tests. Automating these tests typically requires a behavior model: A description of the states the application can be in, the transitions between these states, and the expected results. Furthermore one needs scripts to make the abstract actions (transitions) in the model executable. As specifying such behavior models and writing the necessary scripts manually is a hard task, a possible alternative could be to extract them from existing applications. However, mining such models can be a challenge, in particular because one needs to know when two states are equivalent, as well as how to reach that state. We present ProCrawl (PROcess CRAWLer), a generic approach to mine behavior models from (multi-user) enterprise web applications. ProCrawl observes the behavior of the application through its user interface, generates and executes tests to explore unobserved behavior. In our evaluation of three non-trivial web applications (an open-source shop system, an SAP product compliance application, and an open-source conference manager), ProCrawl produces models that precisely abstract application behavior and which can be directly used for effective model-based regression testing.},
 duplicado = {false},
 inserir = {false},
 title = {Mining behavior models from enterprise web applications},
 year = {2013}
}

@article{1918,
 abstract = {Many works related to software engineering rely upon formal models, e.g., to perform model-checking or automatic test case generation. Nonetheless, producing such models is usually tedious and error-prone. Model inference is a research field helping in producing models by generating partial models from documentation or execution traces (observed action sequences). This paper presents a new model generation method combining model inference and expert systems. It appears that an engineer is able to recognise the functional behaviours of an application from its traces by applying deduction rules. We propose a framework, applied to Web applications, simulating this reasoning mechanism, with inference rules organised into layers. Each yields partial IOSTSs (Input Output Symbolic Transition Systems), which become more and more abstract and understandable.},
 duplicado = {false},
 inserir = {false},
 title = {Inferring models with rule-based expert systems},
 year = {2014}
}

@article{1919,
 abstract = {Today�s web applications increasingly rely on client-side code execution. HTML is not just created on the server, but manipulated extensively within the browser through JavaScript code. In this paper, we seek to understand the software engineering implications of this. We look at deviations from many known best practices in such areas of performance, accessibility, and correct structuring of HTML documents. Furthermore, we assess to what extent such deviations manifest themselves through client-side code manipulation only. To answer these questions, we conducted a large scale experiment, involving automated client-enabled crawling of over 4000 web applications, resulting in over 100,000,000 pages analyzed, and close to 1,000,000 unique client-side user interface states. Our findings show that the majority of sites contain a substantial number of problems, making sites unnecessarily slow, inaccessible for the visually impaired, and with layout that is unpredictable due to errors in the dynamically modified DOM trees.},
 duplicado = {false},
 inserir = {false},
 title = {Software engineering for the web: the state of the practice},
 year = {2014}
}

@article{1920,
 abstract = {Due to the increasing popularity of web applications, and the number of browsers and platforms on which such applications can be executed, cross-browser incompatibilities (XBIs) are becoming a serious concern for organizations that develop web-based software. Most of the techniques for XBI detection developed to date are either manual, and thus costly and error-prone, or partial and imprecise, and thus prone to generating both false positives and false negatives. To address these limitations of existing techniques, we developed X-PERT, a new automated, precise, and comprehensive approach for XBI detection. X-PERT combines several new and existing differencing techniques and is based on our findings from an extensive study of XBIs in real-world web applications. The key strength of our approach is that it handles each aspects of a web application using the differencing technique that is best suited to accurately detect XBIs related to that aspect. Our empirical evaluation shows that X-PERT is effective in detecting real-world XBIs, improves on the state of the art, and can provide useful support to developers for the diagnosis and (eventually) elimination of XBIs.},
 duplicado = {false},
 inserir = {false},
 title = {X-PERT: accurate identification of cross-browser issues in web applications},
 year = {2013}
}

@article{1921,
 abstract = {Components of numerous software systems are developed and maintained by multiple stakeholders, and there is significant overlap and synergy in the process of testing systems with shared components. We have designed and implemented infrastructure that enables testers of different components to share their test results and artifacts so that they can collaborate in testing shared components. We also develop an example collaborative testing process that leverages our infrastructure to save effort for regression testing of systems with shared components. Our empirical study of this process shows that collaborative testing of component-based software systems can not only save significant effort by sharing test results and artifacts, but also improve test quality of individual components by utilizing synergistic data shared among component testers.},
 duplicado = {false},
 inserir = {false},
 title = {Enabling collaborative testing across shared software components},
 year = {2014}
}

@article{1922,
 abstract = {Dynamic languages, such as JavaScript, give programmers the freedom to ignore types, and enable them to write concise code in short time. Despite this freedom, many programs follow implicit type rules, for example, that a function has a particular signature or that a property has a particular type. Violations of such implicit type rules often correlate with problems in the program. This paper presents TypeDevil, a mostly dynamic analysis that warns developers about inconsistent types. The key idea is to assign a set of observed types to each variable, property, and function, to merge types based in their structure, and to warn developers about variables, properties, and functions that have inconsistent types. To deal with the pervasiveness of polymorphic behavior in real-world JavaScript programs, we present a set of techniques to remove spurious warnings and to merge related warnings. Applying TypeDevil to widely used benchmark suites and real-world web applications reveals 15 problematic type inconsistencies, including correctness problems, performance problems, and dangerous coding practices.},
 duplicado = {false},
 inserir = {false},
 title = {TypeDevil: dynamic type inconsistency analysis for JavaScript},
 year = {2015}
}

@article{1923,
 abstract = {A consistent cross-browser user experience is crucial for the success of a website. Layout Cross Browser Issues (XBIs) can severely undermine a website�s success by causing web pages to render incorrectly in certain browsers, thereby negatively impacting users� impression of the quality and services that the web page delivers. Existing Cross Browser Testing (XBT) techniques can only detect XBIs in websites. Repairing them is, hitherto, a manual task that is labor intensive and requires significant expertise. Addressing this concern, our paper proposes a technique for automatically repairing layout XBIs in websites using guided search-based techniques. Our empirical evaluation showed that our approach was able to successfully fix 86% of layout XBIs reported for 15 different web pages studied, thereby improving their cross-browser consistency.},
 duplicado = {false},
 inserir = {true},
 title = {Automated repair of layout cross browser issues using search-based techniques},
 year = {2017}
}

@article{1924,
 abstract = {JavaScript has become one of the most popular programming languages, yet it is known for its suboptimal design. To effectively use JavaScript despite its design flaws, developers try to follow informal code quality rules that help avoid correctness, maintainability, performance, and security problems. Lightweight static analyses, implemented in "lint-like" tools, are widely used to find violations of these rules, but are of limited use because of the language's dynamic nature. This paper presents DLint, a dynamic analysis approach to check code quality rules in JavaScript. DLint consists of a generic framework and an extensible set of checkers that each addresses a particular rule. We formally describe and implement 28 checkers that address problems missed by state-of-the-art static approaches. Applying the approach in a comprehensive empirical study on over 200 popular web sites shows that static and dynamic checking complement each other. On average per web site, DLint detects 49 problems that are missed statically, including visible bugs on the web sites of IKEA, Hilton, eBay, and CNBC.},
 duplicado = {false},
 inserir = {false},
 title = {DLint: dynamically checking bad coding practices in JavaScript},
 year = {2015}
}

@article{1925,
 abstract = {As the mobile platform continues to pervade all aspects of human activity, and mobile applications, or mobile apps for short, on this platform tend to be faulty just like other types of software, there is a growing need for automated testing techniques for mobile apps. Modelbased testing is a popular and important testing approach that operates on a model of an app's behavior. However, such a model is often not available or of insufficient quality. To address this issue, we present a novel grey-box approach for automatically extracting a model of a given mobile app. In our approach, static analysis extracts the set of events supported by the Graphical User Interface (GUI) of the app. Then dynamic crawling reverse-engineers a model of the app, by systematically exercising these events on the running app. We also present a tool implementing this approach for the Android platform. Our empirical evaluation of this tool on several Android apps demonstrates that it can efficiently extract compact yet reasonably comprehensive models of high quality for such apps.},
 duplicado = {false},
 inserir = {false},
 title = {A grey-box approach for automated GUI-model generation of mobile applications},
 year = {2013}
}

@article{1928,
 abstract = {JavaScript has become one of the most prevalent programming languages. Unfortunately, some of the unique properties that contribute to this popularity also make JavaScript programs prone to errors and difficult for program analyses to reason about. These properties include the highly dynamic nature of the language, a set of unusual language features, a lack of encapsulation mechanisms, and the �no crash� philosophy. This article surveys dynamic program analysis and test generation techniques for JavaScript targeted at improving the correctness, reliability, performance, security, and privacy of JavaScript-based software.},
 duplicado = {false},
 inserir = {false},
 title = {A Survey of Dynamic Analysis and Test Generation for JavaScript},
 year = {2017}
}

@article{1931,
 abstract = {Abstract
In this paper, we present ALEX, a web application that enables non-programmers to fully automatically infer models of web applications via active automata learning. It guides the user in setting up dedicated learning scenarios, and invites her to experiment with the available options in order to infer models at adequate levels of abstraction. In the course of this process, characteristics that go beyond a mere �site map� can be revealed, such as hidden states that are often either specifically designed or indicate errors in the application logic. Characteristic for ALEX is its support for mixed-mode learning: REST and web services can be executed simultaneously in one learning experiment, which is ideal when trying to compare back-end and front-end functionality of a web application. ALEX has been evaluated in a comparative study with 140 undergraduate students, which impressively highlighted its potential to make formal methods like active automata learning more accessible to a non-expert crowd.},
 duplicado = {false},
 inserir = {false},
 title = {ALEX: Mixed-Mode Learning of Web Applications at Ease},
 year = {2016}
}

@article{1932,
 abstract = {Abstract
Software is constantly evolving and to successfully comprehend and manage this evolutionary change is a challenging task which requires traceability support. In this paper we propose a novel approach to traceability as a cornerstone for successful impact analysis and change management, in the context of collaborative software quality management. We first motivate the crucial role of traceability within lifecycle management of the new generation of distributed fragmented software services. Based on the model-based collaborative software quality management framework of Living Models, we then categorize software quality management services and identify novel types of traceability. This is followed by an overview and classification of sample software quality management services from literature, enabled by the interrelation with the identified types of traceability. From this classification we derive the need for further research on traceability in collaborative software quality management.},
 duplicado = {false},
 inserir = {false},
 title = {Traceability Types for Mastering Change in Collaborative Software Quality Management},
 year = {2016}
}

@article{1933,
 abstract = {Abstract
In order to remain useful test scripts must evolve parallel to the test objects they are intended to test. In the approach described here the test objects are web services whose test script is derived from the web service interface definition. The test script structure is automatically generated from the WSDL structure with tags and attributes, however, the content, i.e. the test data has to be inserted by hand. From this script service requests are automatically generated and service responses automatically validated. As with other generated software artifacts, once the structure of the interface or the logic of the targeted service is changed, the content of the test script is no longer valid. It has to be altered and/or enhanced to fit the new interface structure and/or the altered service logic. In this paper the author proposes a semi-automated approach to solving this test maintenance problem and explains how it has been implemented in a web service testing tool by employing data reverse engineering techniques. The author also report on his experience with the approach when maintaining a test in the field.},
 duplicado = {false},
 inserir = {false},
 title = {Web Service Test Evolution},
 year = {2016}
}

@article{1934,
 abstract = {Abstract:
To determine how industry and academia approach software testing, researchers compared the titles of presentations from selected conferences in each of the two communities. The results shed light on the root cause of low industry-academia collaboration and led to suggestions on how to improve this situation.},
 duplicado = {false},
 inserir = {false},
 title = {Worlds Apart: Industrial and Academic Focus Areas in Software Testing},
 year = {2017}
}

@article{1935,
 abstract = {Abstract
Nowadays, software systems have become an essential element in our daily life. To ensure the quality and operation of software, testing activities have become primordial in the software development life cycle (SDLC). Indeed, software bugs can potentially cause dramatic consequences if the product is released to the end user without testing. The software testing role is to verify that the actual result and the expected result are consistent and ensure that the system is delivered without bugs. Many techniques, approaches and tools have been proposed to help check that the system is defect free. In this paper, we highlight two software testing techniques considered among the most used techniques to perform software tests, and then we perform a comparative study of these techniques, the approaches that supports studied techniques, and the tools used for each technique. We have selected the first technique based on the 2014 survey [62] that heighted the motivations for using the Model-based-testing, and by analyzing the survey results we have found that some MBT limits are benefits in Risk based testing, the second technique in our study.},
 duplicado = {false},
 inserir = {false},
 title = {A Comparative Study of Software Testing Techniques},
 year = {2014}
}

@article{1937,
 abstract = {Abstract
Risk assessment is dependent on its application domain. Risk values consist of probability and impact factors, but there is no fixed, unique guideline for the determination of these two factors. For a precise risk-value calculation, an adequate collection of factors is crucial. In this paper, we show the evolution from the first phase until the application of a risk assessment approach in the area of an international insurance company. In such a risk-aware field we have to systematically determine relevant factors and their severity. The final results are melted into a calculation tool that is embedded in the companies development process and used for decision support system. This paper shows the results and observations for the whole implementation process achieved via action research.},
 duplicado = {false},
 inserir = {false},
 title = {Integrating a Lightweight Risk Assessment Approach into an Industrial Development Process},
 year = {2016}
}

@article{1938,
 abstract = {Abstract
Risk orientation in testing is an important means to balance quality, time-to-market, and cost of software. Especially for small and medium enterprises (SME) under high competitive and economic pressure, risk orientation can help to focus testing activities on critical areas of a software product. Although several risk-based approaches to testing are available, the topic has so far not been investigated in the context of SME, where risks are often associated with business critical issues. This article fills the gap and explores the state of risk orientation in the testing processes of SME. Furthermore, it compares the state of risk-based testing in SME to the situation in large enterprises. The article is based on a multiple case study conducted with five SME. A previous study on risk-based testing in large enterprises is used as reference for investigating the differences between risk orientation in SME and large enterprises. The findings of our study show that a strong business focus, the use of informal risk concepts, as well as the application of risk knowledge to reduce testing cost and time are key differences of risk-based testing in SME compared to large enterprises.},
 duplicado = {false},
 inserir = {false},
 title = {Risk orientation in software testing processes of small and medium enterprises: an exploratory and comparative study},
 year = {2016}
}

@article{1939,
 abstract = {Abstract:
Systematic defect management based on bug-tracking systems such as Bugzilla is well established and has been successfully used in many software organizations. Defect management weights the failures observed during test execution according to their severity and forms the basis for effective defect taxonomies. In practice, most defect taxonomies are used only for the a posteriori allocation of testing resources to prioritize failures for debugging. Thus, these taxonomies' full potential to control and improve all the steps of testing has remained unexploited. This is especially the case for testing a system's user requirements. System-level defect taxonomies can improve the design of requirements-based tests, the tracing of defects to requirements, the quality assessment of requirements, and the control of the relevant defect management. So, we developed requirements-based testing with defect taxonomies (RTDT). This approach is aligned with the standard test process and uses defect taxonomies to support all phases of testing requirements. To illustrate this approach and its benefits, we use an example project (which we call Project A) from a public health insurance institution.},
 duplicado = {false},
 inserir = {false},
 title = {Using Defect Taxonomies for Testing Requirements},
 year = {2014}
}

@article{1940,
 abstract = {Abstract
Context

It is a difficult and challenging task to fully automatize model-based testing because this demands complete and unambiguous system models as input. Therefore, in practice, test cases, especially on the system level, are still derived manually from behavioral models like UML activity diagrams or state machines. But this kind of manual test case derivation is error-prone and knowing these errors makes it possible to provide guidelines to reduce them.

Objective

The objective of the study presented in this paper therefore is to examine which errors are possible and actually made when manually deriving test cases from UML activity diagrams or state machines and whether there are differences between these diagram types.

Method

We investigate the errors made when deriving test cases manually in a controlled student experiment. The experiment was performed and internally replicated with overall 84 participants divided into three groups at two institutions.

Results

As a result of our experiment, we provide a taxonomy of errors made and their frequencies. In addition, our experiment provides evidence that activity diagrams have a higher perceived comprehensibility but also a higher error-proneness than state machines with regard to manual test case derivation. This information helps to develop guidelines for manual test case derivation from UML activity diagrams and state machines.

Conclusion

Most errors observed were due to missing test steps, conditions or results, or content was written into the wrong field. As activity diagrams have a higher perceived comprehensibility, but also more error-prone than state machines, both diagram types are useful for manual test case derivation. Their application depends on the context and should be complemented with clear rules on how to derive test cases.},
 duplicado = {false},
 inserir = {false},
 title = {Manual test case derivation from UML activity diagrams and state machines: A controlled experiment},
 year = {2015}
}

@article{1941,
 abstract = {Abstract:
This special issue, owing to its fundamental software quality focus, comprises a collection of diverse articles that address the challenges and directions for software quality research. The Web extra at http://youtu.be/T7V4RSr1KEE is an audio interview in which Davide Falessi speaks with guest editors Annie Kuntzmann-Combelles, Michael Felderer, and Ruth Breu about methods for improving software quality management, testing, and security on intelligent and interconnected devices.},
 duplicado = {false},
 inserir = {false},
 title = {New Perspectives on Software Quality [Guest editors' introduction]},
 year = {2014}
}

@article{1942,
 abstract = {Abstract
Software testing has often to be done under severe pressure due to limited resources and a challenging time schedule facing the demand to assure the fulfillment of the software requirements. In addition, testing should unveil those software defects that harm the mission-critical functions of the software. Risk-based testing uses risk (re-)assessments to steer all phases of the test process to optimize testing efforts and limit risks of the software-based system. Due to its importance and high practical relevance, several risk-based testing approaches were proposed in academia and industry. This paper presents a taxonomy of risk-based testing providing a framework to understand, categorize, assess, and compare risk-based testing approaches to support their selection and tailoring for specific purposes. The taxonomy is aligned with the consideration of risks in all phases of the test process and consists of the top-level classes risk drivers, risk assessment, and risk-based test process. The taxonomy of risk-based testing has been developed by analyzing the work presented in available publications on risk-based testing. Afterwards, it has been applied to the work on risk-based testing presented in this special section of the International Journal on Software Tools for Technology Transfer.},
 duplicado = {false},
 inserir = {false},
 title = {A taxonomy of risk-based testing},
 year = {2014}
}

@article{1943,
 abstract = {Abstract
The simultaneous adoption of CMMI and RUP allows the definition of �what to do� (with the support of CMMI) and �how to do� (with the support of RUP) in the context of executing software development projects. In this paper, our main contribution relates to the alignment of CMMI ML2 with RUP, in the context of executing software projects and the analysis of RUP coverage. We present the alignment for CMMI ML2 process areas, incorporating priority mechanisms. The adopted case study allows the analysis of the way RUP supports CMMI ML2 process areas taking into account the proposed alignment and the theoretical coverage analyzed. For particular process areas, RUP can be considered a good approach for CMMI ML2 implementation.},
 duplicado = {false},
 inserir = {false},
 title = {RUP Alignment and Coverage Analysis of CMMI ML2 Process Areas for the Context of Software Projects Execution},
 year = {2014}
}

@article{1944,
 abstract = {Abstract
In many development projects, testing has to be conducted under severe pressure due to limited resources and a challenging time schedule. Risk-based testing, which utilizes identified risks of the system for testing purposes, has a high potential to improve testing as it helps to optimize the allocation of resources and provides decision support for management. But for many organizations, the integration of a risk-based approach into established testing activities is a challenging task, and there are several options to do so. In this article, we analyze how risk is defined, assessed, and applied to support and improve testing activities in projects, products, and processes. We investigate these questions empirically by a multiple case study of currently applied risk-based testing activities in industry. The case study is based on three cases from different backgrounds, i.e., a test project in context of the extension of a large Web-based information system, product testing of a measurement and diagnostic equipment for the electrical power industry, as well as a test process of a system integrator of telecommunication solutions. By analyzing and comparing these different industrial cases, we draw conclusions on the state of risk-based testing and discuss possible improvements.},
 duplicado = {false},
 inserir = {false},
 title = {A multiple case study on risk-based testing in industry},
 year = {2014}
}

@article{1946,
 abstract = {Abstract
At the analysis phase of an enterprise information system development, the alignment between the process level requirements (information systems) with the product level requirements (software system) may not be properly achieved. Modeling the processes for the enterprise�s business is often insufficient for implementation teams, and implementation requirements are often misaligned with business and stakeholder needs. In this paper, we demonstrate, though a real industrial case, how transition steps and rules are used to assure that process- and product-level requirements are aligned, within an approach that supports the creation of the intended requirements. The input for the transition steps is an information system logical architecture, and the output is a product-level (software) use case model.},
 duplicado = {false},
 inserir = {false},
 title = {A Demonstration Case on Steps and Rules for the Transition from Process-Level to Software Logical Architectures in Enterprise Models},
 year = {2013}
}

